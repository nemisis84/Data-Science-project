Scale-dependent error:

- RMSE (Root Mean Square Error): This is a measure of the average magnitude of the errors. It gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable. The values are quite high, which might indicate that the model has a significant average error per data point.
- MAE (Mean Absolute Error): This measures the average magnitude of the errors in a set of predictions, without considering their direction. It's a linear score, which means all individual differences are weighted equally in the average. In your case, the MAE is also quite high, which could suggest that on average, the model's predictions are off by the amount indicated by the MAE.

Percentage error:
- MAPE (Mean Absolute Percentage Error): This is a measure of prediction accuracy of a forecasting method in statistics, for example in trend estimation, also known as mean absolute percentage deviation (MAPD). It usually expresses accuracy as a percentage, and it's defined as the average absolute percent error for each time period minus actual values divided by actual values. In your case, the MAPE is very close to 1 (or 100%) on the training set, which suggests that the model's predictions are on average almost 100% away from the actual values. This is typically seen as a poor outcome.
- R² (R-squared): This is the coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points. An R² of 1 indicates that the regression predictions perfectly fit the data. In your plot, the R² value on the training set is around 0.91, which suggests a fairly good fit to the training data. However, the R² on the test set is significantly lower, around 0.29, indicating that the model does not perform well on unseen data.